{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67589c0a",
   "metadata": {},
   "source": [
    "# <font color='blue'>Prever a cotação do BTC com Pyspark</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b1551f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versão da linguagem py usada neste jupyter notebook: 3.9.12\n"
     ]
    }
   ],
   "source": [
    "# Versão da Linguagem Python\n",
    "from platform import python_version\n",
    "print('Versão da linguagem py usada neste jupyter notebook:', python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afc6fc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar o findspark e inicializa\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d48f9a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pyspark\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.mllib.evaluation import RegressionMetrics\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml.feature import MinMaxScaler\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator, CrossValidatorModel\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4510c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output formatting\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_colwidth', 400)\n",
    "from matplotlib.axes._axes import _log as matplotlib_axes_logger\n",
    "matplotlib_axes_logger.setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18362ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: pedrolocosta from EngIA\n",
      "\n",
      "seaborn   : 0.11.2\n",
      "matplotlib: 3.5.2\n",
      "numpy     : 1.22.4\n",
      "pandas    : 1.4.2\n",
      "sys       : 3.9.12 (main, Apr  5 2022, 06:56:58) \n",
      "[GCC 7.5.0]\n",
      "findspark : 2.0.1\n",
      "pyspark   : 3.3.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Version of packages used in this jupyter notebook\n",
    "%reload_ext watermark\n",
    "%watermark -a \"pedrolocosta from EngIA\" --iversions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4c953d",
   "metadata": {},
   "source": [
    "## Preparing the Spark environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e66c457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for notebook reproducibility\n",
    "rnd_seed = 23\n",
    "np.random.seed = rnd_seed\n",
    "np.random.set_state = rnd_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71e7c2fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/07/18 06:45:06 WARN Utils: Your hostname, jarvis resolves to a loopback address: 127.0.1.1; using 192.168.100.33 instead (on interface wlp1s0)\n",
      "22/07/18 06:45:06 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/07/18 06:45:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Create Spark Context\n",
    "sc = SparkContext(appName = \"py_small_project_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e13b67ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Spark session\n",
    "spark_session = SparkSession.Builder().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e359dfa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.100.33:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>py_small_project_3</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f223c152940>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View object 'spark_session'\n",
    "spark_session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901d291b",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9539677b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Load data from Spark session\n",
    "df_spark = spark_session.read.csv('dados/dataset_bitcoin.csv', header = 'true', inferSchema = 'true')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75667490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Object type\n",
    "type(df_spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6f83d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+----+----+-----+------------+-----------------+--------------+\n",
      "| Timestamp|Open|High| Low|Close|Volume_(BTC)|Volume_(Currency)|Weighted_Price|\n",
      "+----------+----+----+----+-----+------------+-----------------+--------------+\n",
      "|1325317920|4.39|4.39|4.39| 4.39|  0.45558087|     2.0000000193|          4.39|\n",
      "|1325319300| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|\n",
      "|1325319360| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|\n",
      "|1325319420| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|\n",
      "|1325319480| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|\n",
      "|1325319540| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|\n",
      "|1325319600| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|\n",
      "|1325319660| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|\n",
      "|1325345040| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|\n",
      "|1325345100| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|\n",
      "|1325345160| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|\n",
      "|1325345220| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|\n",
      "|1325345280| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|\n",
      "|1325345340| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|\n",
      "|1325345400| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|\n",
      "|1325345460| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|\n",
      "|1325345520| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|\n",
      "|1325345580| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|\n",
      "|1325345640| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|\n",
      "|1325345700| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|\n",
      "+----------+----+----+----+-----+------------+-----------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View the data\n",
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74bed19a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Timestamp: integer (nullable = true)\n",
      " |-- Open: double (nullable = true)\n",
      " |-- High: double (nullable = true)\n",
      " |-- Low: double (nullable = true)\n",
      " |-- Close: double (nullable = true)\n",
      " |-- Volume_(BTC): double (nullable = true)\n",
      " |-- Volume_(Currency): double (nullable = true)\n",
      " |-- Weighted_Price: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View the schema\n",
    "df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e0b1eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4856600"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View number of lines\n",
    "df_spark.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a812a921",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
